import os
from curl_cffi import requests
from bs4 import BeautifulSoup
import sys
import re

# --- ×”×’×“×¨×•×ª ---
HOMEPAGE_URL = "https://www.fragrantica.com/"
LAST_SEEN_FILE = "last_seen_perfume.txt"

# --- ×©×œ×™×¤×ª ××¤×ª×—×•×ª Pushover ---
PUSHOVER_USER_KEY = os.environ.get("PUSHOVER_USER_KEY")
PUSHOVER_API_TOKEN = os.environ.get("PUSHOVER_API_TOKEN")

def send_pushover_notification(title, message, url_link=None):
    if not PUSHOVER_USER_KEY or not PUSHOVER_API_TOKEN:
        print("âŒ ×©×’×™××”: ×—×¡×¨×™× ××¤×ª×—×•×ª Pushover.")
        return

    endpoint = "https://api.pushover.net/1/messages.json"
    
    payload = {
        "token": PUSHOVER_API_TOKEN,
        "user": PUSHOVER_USER_KEY,
        "title": title,
        "message": message,
        "html": 1,
        "priority": 0
    }

    if url_link:
        payload["url"] = url_link
        payload["url_title"] = "ğŸ‘‰ ×œ×—×¥ ×œ×¢××•×“ ×”×‘×•×©×"

    try:
        import requests as orig_requests
        orig_requests.post(endpoint, data=payload, timeout=10)
        print("âœ… ×”×ª×¨××ª Pushover × ×©×œ×—×”!")
    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×—×™×‘×•×¨ ×œ-Pushover: {e}")

def get_last_seen_link():
    if not os.path.exists(LAST_SEEN_FILE):
        return None
    with open(LAST_SEEN_FILE, "r", encoding="utf-8") as f:
        return f.read().strip()

def save_last_seen_link(link):
    with open(LAST_SEEN_FILE, "w", encoding="utf-8") as f:
        f.write(link)

def get_first_perfume_on_page(soup):
    """
    ×‘××§×•× ×œ×—×¤×© ×›×•×ª×¨×•×ª, ×¤×©×•×˜ ×©×•×œ×£ ××ª ×”×œ×™× ×§ ×”×ª×§×™×Ÿ ×”×¨××©×•×Ÿ ×œ×‘×•×©× ×©× ××¦× ×‘×¢××•×“.
    ×‘×¤×¨×’×¨× ×˜×™×§×”, ×”×œ×™× ×§×™× ×”×¨××©×•× ×™× ×‘×§×•×“ ×”× ×ª××™×“ ××”×§×¨×•×¡×œ×” ×©×œ ×”×—×“×©×™×.
    """
    try:
        # ××—×¤×© ××ª ×›×œ ×”×œ×™× ×§×™× ×‘×¢××•×“ ×©××›×™×œ×™× /perfume/
        # ×•××¡× ×Ÿ ×›×ª×‘×•×ª (/news/) ××• ×“×¤×™ ×—×™×¤×•×©
        candidates = soup.find_all("a", href=True)
        
        print(f"ğŸ” × ××¦××• {len(candidates)} ×œ×™× ×§×™× ×‘×¢××•×“. ××¡× ×Ÿ...")

        for link in candidates:
            href = link['href']
            
            # ×ª× ××™ ×¡×™× ×•×Ÿ ×§×¤×“× ×™×™×:
            # 1. ×—×™×™×‘ ×œ×”×™×•×ª ×œ×™× ×§ ×œ×‘×•×©×
            # 2. ×—×™×™×‘ ×œ×”×¡×ª×™×™× ×‘-.html
            # 3. ××¡×•×¨ ×©×™×”×™×” ×œ×™× ×§ ×œ×›×ª×‘×”
            # 4. ××¡×•×¨ ×©×™×”×™×” ×œ×™× ×§ ×œ××•×ª×’ (designers)
            if '/perfume/' in href and '.html' in href and '/news/' not in href and '/designers/' not in href:
                
                full_link = "https://www.fragrantica.com" + href if not href.startswith('http') else href
                
                # ×—×™×œ×•×¥ ×©× ×”×‘×•×©×
                perfume_name = link.get_text(strip=True)
                
                # ×× ××™×Ÿ ×˜×§×¡×˜ ×‘×œ×™× ×§, × × ×¡×” ×œ××¦×•× ×ª××•× ×” ×‘×ª×•×›×• (×‘×“×¨×š ×›×œ×œ ×‘×§×¨×•×¡×œ×” ×–×” ×ª××•× ×”)
                if not perfume_name:
                    img = link.find("img")
                    if img and img.get('alt'):
                        perfume_name = img['alt']
                
                # ×× ×’× ×•×Ÿ ×—×™×¨×•×: ×—×™×œ×•×¥ ×©× ××ª×•×š ×”×œ×™× ×§ ×¢×¦××•
                if not perfume_name:
                    parts = href.split('/')
                    if len(parts) > 2:
                        raw_name = parts[-1].replace('.html', '')
                        perfume_name = re.sub(r'-\d+$', '', raw_name).replace('-', ' ')

                # ××—×–×™×¨ ××ª ×”×¨××©×•×Ÿ ×©× ××¦× (×•×–×”×•, ×™×•×¦××™× ××”×¤×•× ×§×¦×™×”)
                return {
                    'title': perfume_name,
                    'link': full_link
                }
                
        return None

    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘× ×™×ª×•×— ×”-HTML: {e}")
        return None

def main():
    print("ğŸš€ ×”×‘×•×˜ ××ª×—×™×œ ×‘×¡×¨×™×§×” (××¦×‘ ×—×™×¤×•×© ×œ×™× ×§×™× ×™×©×™×¨)...")
    
    try:
        # ×”×•×¨×“×ª ×”×¢××•×“
        response = requests.get(HOMEPAGE_URL, impersonate="chrome", timeout=20)
        
        if response.status_code != 200:
            print(f"âŒ ×©×’×™××” ×‘×’×™×©×” ×œ××ª×¨: {response.status_code}")
            sys.exit(1)
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ×”×“×¤×¡×ª ×”×›×•×ª×¨×ª ×©×œ ×”×¢××•×“ ×›×“×™ ×œ×•×•×“× ×©×× ×—× ×• ×‘××§×•× ×”× ×›×•×Ÿ
        print(f"ğŸ“„ ×›×•×ª×¨×ª ×”×¢××•×“ ×©× ×¡×¨×§: {soup.title.string if soup.title else '×œ× × ××¦××” ×›×•×ª×¨×ª'}")

        # ×”×¤×¢×œ×ª ×”×œ×•×’×™×§×” ×”×—×“×©×”
        newest_perfume = get_first_perfume_on_page(soup)
        
        if not newest_perfume:
            print("âš ï¸ ××•×–×¨ ×××•×“. ×œ× ××¦××ª×™ ×©×•× ×œ×™× ×§ ×œ×‘×•×©× ×‘×¢××•×“ ×”×‘×™×ª.")
            # ×”×“×¤×¡×ª ×—×œ×§ ××”-HTML ×œ×“×™×‘×•×’ (×¨×§ ×”-500 ×ª×•×•×™× ×”×¨××©×•× ×™×) ×× × ×›×©×œ
            # print(soup.prettify()[:500]) 
            return

        latest_title = newest_perfume['title']
        latest_link = newest_perfume['link']
        
        print(f"ğŸ‘€ ×”×‘×•×©× ×”×¨××©×•×Ÿ ×©× ××¦×: {latest_title}")
        
        last_seen = get_last_seen_link()
        
        if latest_link != last_seen:
            print("âœ¨ ×©×™× ×•×™ ×–×•×”×”! ×©×•×œ×— ×”×ª×¨××”...")
            
            msg_body = (
                f"ğŸ‰ <b>×‘×•×©× ×—×“×© (××• ×©×™× ×•×™ ×‘×§×¨×•×¡×œ×”)!</b><br>"
                f"×©×: {latest_title}<br>"
            )
            
            send_pushover_notification(
                title="New Perfume Alert ğŸ§´",
                message=msg_body,
                url_link=latest_link
            )
            
            save_last_seen_link(latest_link)
        else:
            print("ğŸ˜´ ×–×” ××•×ª×• ×‘×•×©× ×›××• ×‘×¤×¢× ×”×§×•×“××ª.")

    except Exception as e:
        print(f"âŒ ×§×¨×™×¡×” ×›×œ×œ×™×ª: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
